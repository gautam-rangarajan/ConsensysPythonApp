{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import sys\n",
    "\n",
    "# Get the current working directory of the Jupyter notebook\n",
    "notebook_directory = os.getcwd()\n",
    "# Assuming the notebook is in the 'bin/' folder, add the parent directory to sys.path\n",
    "parent_directory = os.path.dirname(notebook_directory)\n",
    "sys.path.append(parent_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import timeit\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "cache_file = Path(\"movie_synopsis_cache.json\")\n",
    "\n",
    "# Function to load cache data from a file\n",
    "def load_cache():\n",
    "    if cache_file.is_file() and cache_file.stat().st_size > 0:\n",
    "        with open(cache_file, 'r') as file:\n",
    "            try:\n",
    "                return json.load(file)\n",
    "            except json.JSONDecodeError:\n",
    "                return {}\n",
    "    return {}\n",
    "\n",
    "# Function to save cache data to a file\n",
    "def save_cache(cache):\n",
    "    with open(cache_file, 'w') as file:\n",
    "        json.dump(cache, file, indent=4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from imdb import Cinemagoer\n",
    "# Create an instance of the Cinemagoer class\n",
    "cg = Cinemagoer()\n",
    "\n",
    "# Create methods to fetch movie details given a list of imdb movie ids\n",
    "def get_movie_details(imdb_id):\n",
    "    cache = load_cache()\n",
    "\n",
    "    # Check if the movie data is in cache\n",
    "    if imdb_id in cache:\n",
    "        print(\"Retrieved from cache.\")\n",
    "        return cache[imdb_id]\n",
    "\n",
    "    # If not in cache, get movie data\n",
    "    start = timeit.default_timer()\n",
    "    cg_imdb_id = imdb_id.replace(\"tt\", \"\")\n",
    "    movie = cg.get_movie(cg_imdb_id)\n",
    "    end = timeit.default_timer()\n",
    "    print(\"get_movie_details took {} seconds to run\".format(end - start))\n",
    "    result = {}\n",
    "\n",
    "    keys = [\"title\", \"genres\", \"runtimes\", \"original air date\", \"rating\", \"votes\", \"imdbID\", \"language codes\", \"year\", \"director\", \"cast\"]\n",
    "    for key in keys:\n",
    "        if key not in movie:\n",
    "            result[key] = None\n",
    "        elif key == \"cast\":\n",
    "            result[key] = [c.personID for c in movie[key][:5]]\n",
    "        elif key == \"director\":\n",
    "            result[key] = [c.personID for c in movie[key]]\n",
    "        else:\n",
    "            result[key] = movie.get(key, None)\n",
    "\n",
    "    synopsis_present = True if \"synopsis\" in movie and len(movie[\"synopsis\"]) > 0 else False\n",
    "    plot_present = True if \"plot\" in movie and len(movie[\"plot\"]) > 0 else False\n",
    "    if synopsis_present and plot_present:\n",
    "        result[\"synopsis\"] = movie[\"synopsis\"][0]\n",
    "        result[\"plot\"] = movie[\"plot\"][0]\n",
    "    elif synopsis_present:\n",
    "        result[\"synopsis\"] = movie[\"synopsis\"][0]\n",
    "        result[\"plot\"] = movie[\"synopsis\"][0]\n",
    "    elif plot_present:\n",
    "        result[\"synopsis\"] = movie[\"plot\"][0]\n",
    "        result[\"plot\"] = movie[\"plot\"][0]\n",
    "    else:\n",
    "        result[\"synopsis\"] = \"\"\n",
    "        result[\"plot\"] = \"\"\n",
    "\n",
    "    # Save the new data to cache\n",
    "    cache[imdb_id] = result\n",
    "    save_cache(cache)\n",
    "    return result\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_fixed(1))  # Retries up to 3 times with a 1-second wait between tries\n",
    "def get_movie_details_with_retry(movie):\n",
    "    return get_movie_details(movie)\n",
    "\n",
    "def get_movie_details_as_data_frame(movie_list):\n",
    "    all_movie_details = {}\n",
    "    for movie in movie_list:\n",
    "        all_movie_details[movie] = get_movie_details_with_retry(movie)\n",
    "    all_movie_details = [all_movie_details[movie] for movie in movie_list if movie in all_movie_details]\n",
    "    return pd.json_normalize(all_movie_details)\n",
    "\n",
    "print(get_movie_details_as_data_frame([\"tt6166392\", \"tt4046784\"]))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import requests\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Given a date range, fetch all the movies that were released during that period.\n",
    "# Additional filters like language/minimum vote count can also be specified\n",
    "MINIMUM_VOTE_COUNT = 50\n",
    "LANGUAGES = [\"en\"]\n",
    "\n",
    "def get_tmdb_movies_in_range(start, end):\n",
    "    api_key = '0b2cc6b5655e6c00206bd71118d1156f'\n",
    "    languages = \",\".join(LANGUAGES)\n",
    "    url = f'https://api.themoviedb.org/3/discover/movie?api_key={api_key}&primary_release_date.gte={start}&primary_release_date.lte={end}&include_adult=false&include_video=false&with_original_language={languages}&page=1&sort_by=popularity.desc&vote_count.gte={MINIMUM_VOTE_COUNT}'\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    total_pages = data[\"total_pages\"]\n",
    "    total_results = data[\"total_results\"]\n",
    "    movies_in_date_range = []\n",
    "    print(f\"total_results: {total_results}\")\n",
    "\n",
    "    for page in range(total_pages):\n",
    "        try:\n",
    "            url = f'https://api.themoviedb.org/3/discover/movie?api_key={api_key}&primary_release_date.gte={start}&primary_release_date.lte={end}&include_adult=false&include_video=false&with_original_language={languages}&page={page+1}&sort_by=popularity.desc'\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            movies_in_date_range.extend(data[\"results\"])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(.1)\n",
    "    print(f\"total_results extracted: {len(movies_in_date_range)}\")\n",
    "    return movies_in_date_range\n",
    "\n",
    "def get_imdb_ids_for_tmdb_movies_in_range(start, end):\n",
    "    api_key = '0b2cc6b5655e6c00206bd71118d1156f'\n",
    "\n",
    "    movies = get_tmdb_movies_in_range(start, end)\n",
    "    imdb_ids = []\n",
    "    found_movies = []\n",
    "    low_votes_movies = []\n",
    "    missing_movies = []\n",
    "    for movie in movies:\n",
    "        try:\n",
    "            id = movie[\"id\"]\n",
    "            url = f\"https://api.themoviedb.org/3/movie/{id}/external_ids?api_key={api_key}\"\n",
    "            response = requests.get(url)\n",
    "            data = response.json()\n",
    "            imdb_id = data[\"imdb_id\"]\n",
    "            if imdb_id is not None:\n",
    "                if int(movie[\"vote_count\"]) >= MINIMUM_VOTE_COUNT:\n",
    "                    imdb_ids.append(imdb_id)\n",
    "                    found_movies.append((id, movie[\"original_title\"], movie[\"vote_count\"]))\n",
    "                else:\n",
    "                    low_votes_movies.append((id, movie[\"original_title\"], movie[\"vote_count\"]))\n",
    "            else:\n",
    "                missing_movies.append((id, movie[\"original_title\"], movie[\"vote_count\"]))\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            time.sleep(1)\n",
    "    print(f\"Number of imdb ids extracted: {len(imdb_ids)}\")\n",
    "    print(f\"Missing movies: {missing_movies}\")\n",
    "    print(f\"Low votes movies: {low_votes_movies}\")\n",
    "    print(f\"Found movies: {found_movies}\")\n",
    "    return imdb_ids\n",
    "\n",
    "yesterday = (datetime.now() - timedelta(1)).strftime('%Y-%m-%d') # Eventually, we will use this in the cron job that runs to populate for the last 'n' days\n",
    "start = \"2023-01-01\"\n",
    "end = \"2023-12-31\"\n",
    "imdb_movie_ids = get_imdb_ids_for_tmdb_movies_in_range(start, end)\n",
    "\n",
    "print(imdb_movie_ids)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# For each movie discovered, fetch full details using Cinemagoer\n",
    "movie_details_df = get_movie_details_as_data_frame(imdb_movie_ids)\n",
    "titles_with_synopsis = movie_details_df['title'].tolist()\n",
    "synopsis_list = movie_details_df['synopsis'].tolist()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import numpy as np\n",
    "\n",
    "# Initialize tokenizer and model from pre-trained BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to create embeddings for a list of synopses using BERT\n",
    "def get_bert_embeddings(synopses):\n",
    "    embeddings = []\n",
    "    for synopsis in synopses:\n",
    "        # Tokenize the synopsis and convert to input format expected by BERT\n",
    "        inputs = tokenizer(synopsis, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        # Get the output from BERT model\n",
    "        outputs = model(**inputs)\n",
    "        # Use the mean of the last hidden state as the embedding\n",
    "        embedding = outputs.last_hidden_state.mean(dim=1).squeeze().detach().numpy()\n",
    "        embeddings.append(embedding)\n",
    "    return embeddings\n",
    "\n",
    "# Create BERT embeddings for the synopses\n",
    "bert_embeddings = get_bert_embeddings(synopsis_list)\n",
    "bert_embeddings_matrix = np.array(bert_embeddings)\n",
    "print(bert_embeddings_matrix.shape)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#This calculates Cosines similarity between 2 vectors (movies).\n",
    "\n",
    "#Note: Cosine similarity expects 2D matrices.\n",
    "#To perform cosine similarity on vectors, remember to reshape the vector in the 2D shape (1, N), where N is the vector length.\n",
    "#to-do: Update this function to become a weighted cosine, using weights from a file.\n",
    "def get_cosine_similarity(movie_vector_1, movie_vector_2):\n",
    "    cosine_sim = cosine_similarity(movie_vector_1, movie_vector_2)\n",
    "    return cosine_sim\n",
    "\n",
    "#Get the top movies relating to a given movie vector using cosine similarity.\n",
    "#2 use cases for this:\n",
    "# 1. given_movie_vector = a specific movie's embeddings. This will return top movies relating to that movie.\n",
    "# 2. given_movie_vector = user_profile's vector. This will return top movies recommended for this user.\n",
    "\n",
    "def get_top_movies_cosine(tfidf_matrix, given_movie_vector, movie_titles, top_n=5):\n",
    "\n",
    "    # Compute cosine similarity between the movie at movie_index and all movies in the matrix\n",
    "    cosine_similarities = get_cosine_similarity(given_movie_vector, tfidf_matrix).flatten()\n",
    "\n",
    "    # Get the indices of the top_n movies with the highest cosine similarity scores\n",
    "    # Use argsort and reverse it with [::-1] to get the indices in descending order of similarity\n",
    "    # Skip the first one as it is the movie itself with a similarity of 1\n",
    "    similar_indices = cosine_similarities.argsort()[::-1][1:top_n+1]\n",
    "\n",
    "    # Get the scores for the top_n movies\n",
    "    similar_scores = cosine_similarities[similar_indices]\n",
    "\n",
    "    # Combine indices and scores into a list of tuples and return\n",
    "    top_movies = [(movie_titles[index], index, score) for index, score in zip(similar_indices, similar_scores)]\n",
    "\n",
    "    print(f\"Top similar movies to the provided movie vector:\\n\")\n",
    "    for num, (title, index, score) in enumerate(top_movies, start = 1):\n",
    "        print(f\"{num}. \\\"{title}\\\" at ROW {index} with similarity score: {score}\")\n",
    "\n",
    "    return top_movies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for i, title in enumerate(titles_with_synopsis):\n",
    "    print(i, title)\n",
    "\n",
    "get_top_movies_cosine(bert_embeddings_matrix, bert_embeddings_matrix[233].reshape(1, -1), titles_with_synopsis, 5)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
